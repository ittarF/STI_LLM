{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from main import list_files_in_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89GM9ZJW\n",
      "           0  1                                        2\n",
      "11  89GM9ZJW  0  http://www.wikidata.org/entity/Q1318295\n",
      "12  89GM9ZJW  1        http://www.wikidata.org/entity/Q5\n",
      "                                                col0               col1  \\\n",
      "0                                 landesbühne (lenz)     siegfried lenz   \n",
      "1  narrative of a second expedition to the shores...    john richardson   \n",
      "2  the life and travels of thomas simpson, the ar...  alexander simpson   \n",
      "\n",
      "                 col2  \n",
      "0  hoffmann und campe  \n",
      "1         john murray  \n",
      "2     richard bentley  \n"
     ]
    }
   ],
   "source": [
    "from dataClass import DataTable\n",
    "\n",
    "cta_gt_path = 'data/HardTablesR1/DataSets/HardTablesR1/Valid/gt/cta_gt.csv'\n",
    "cta_gt = pd.read_csv(cta_gt_path, header=None)\n",
    "\n",
    "tables_path = 'data/HardTablesR1/DataSets/HardTablesR1/Valid/tables'\n",
    "tables = list_files_in_folder(tables_path)\n",
    "\n",
    "t = DataTable(tables[15])\n",
    "print(t.name)\n",
    "print(cta_gt[cta_gt[0] == '89GM9ZJW'])\n",
    "print(t.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CTA on single column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from dataClass import LamAPI\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "load_dotenv()\n",
    "mistral_api_key = os.getenv(\"MISTRAL_API_KEY\")\n",
    "model = \"open-mixtral-8x7b\"\n",
    "llm = ChatMistralAI(model=model, temperature=0, api_key=mistral_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['landesbühne (lenz)',\n",
       " 'narrative of a second expedition to the shores of the polar sea in the years 1825, 1826, and 1827',\n",
       " 'the life and travels of thomas simpson, the arctic discoverer']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.data.col0.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "def LamAPI2(cell_content):\n",
    "    \n",
    "    url = 'https://lamapi.hel.sintef.cloud/lookup/entity-retrieval'\n",
    "    params = {\n",
    "        'name': f'{cell_content}'.lower(),\n",
    "        'token': os.getenv(\"LAMAPI_KEY\"),\n",
    "        'kg': 'wikidata',\n",
    "        'fuzzy': 'True'\n",
    "    }\n",
    "    headers = {'accept': 'application/json'}\n",
    "\n",
    "    response = requests.get(url, params=params, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        # Process the JSON data here\n",
    "    else:\n",
    "        print(\"Error:\", response.status_code)\n",
    "    \n",
    "    return data\n",
    "\n",
    "cell_content = t.data.iloc[0,0]\n",
    "response = LamAPI2(cell_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313\n"
     ]
    }
   ],
   "source": [
    "types = []\n",
    "for cell_content in t.data.iloc[:,0]:\n",
    "    response = LamAPI2(cell_content)\n",
    "    for entity in response[cell_content]:\n",
    "        for ty in entity['types']:\n",
    "            types.append(ty)\n",
    "print(len(types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 'NEC', '1': 'NEC', '2': 'NEC'}\n"
     ]
    }
   ],
   "source": [
    "t.generate_ner_labels(llm)\n",
    "print(t.ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['street',\n",
       " 'human',\n",
       " 'architectural structure',\n",
       " 'Wikimedia disambiguation page',\n",
       " 'Ortsteil',\n",
       " 'family name',\n",
       " 'taxon',\n",
       " 'locality',\n",
       " 'Bodendenkmal',\n",
       " 'natural monument in Germany',\n",
       " 'human settlement',\n",
       " 'Wikimedia category',\n",
       " 'cadastral municipality of Austria',\n",
       " 'house',\n",
       " 'non-urban municipality in Germany',\n",
       " 'hill',\n",
       " 'mountain',\n",
       " None,\n",
       " 'cultural heritage ensemble',\n",
       " 'church building',\n",
       " 'researcher',\n",
       " 'politician',\n",
       " 'encyclopedia article',\n",
       " 'Wikimedia template',\n",
       " 'municipality seat']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Create a counter for the ids\n",
    "counter = Counter(entity['id'] for entity in types)\n",
    "\n",
    "# Create a unique list of entities based on 'id'\n",
    "unique_entities = {entity['id']: entity for entity in types}.values()\n",
    "\n",
    "# Prepare the data for the dataframe\n",
    "df_data = []\n",
    "for entity in unique_entities:\n",
    "    entity_id = entity['id']\n",
    "    entity_name = entity['name']\n",
    "    count = counter[entity_id]\n",
    "    df_data.append({'id': entity_id, 'name': entity_name, 'count': count})\n",
    "\n",
    "# Create the dataframe\n",
    "df = pd.DataFrame(df_data)\n",
    "\n",
    "candidates = {}\n",
    "for k, (id, name, count) in df.sort_values(by='count', ascending=False).head(25).iterrows():\n",
    "    candidates[name] = id\n",
    "list(candidates.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have to perform Column Table Association.\n",
      "\n",
      "Column Name: col0\n",
      "Column Cells: ['predlitz', 'stadtbergen', 'michelstetten', 'ahorn', 'stillfried', 'oberweg']\n",
      "Candidates: ['street', 'human', 'architectural structure', 'Wikimedia disambiguation page', 'Ortsteil', 'family name', 'taxon', 'locality', 'Bodendenkmal', 'natural monument in Germany', 'human settlement', 'Wikimedia category', 'cadastral municipality of Austria', 'house', 'non-urban municipality in Germany', 'hill', 'mountain', None, 'cultural heritage ensemble', 'church building', 'researcher', 'politician', 'encyclopedia article', 'Wikimedia template', 'municipality seat']\n",
      "\n",
      "Based on the column name and columns cells choose the correct column type among the candidates and return the chosen candidate in the format [[[choosen_type_name]]].\n",
      "Please provide the response strictly in the format [[[choosen_type_name]]]. Do not include any additional text or explanation.\n",
      "Example of your answer:[[[actor]]]Correct candidate: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "col = 'col0'\n",
    "cells = list(t.data[col])\n",
    "prompt = (\n",
    "    'You have to perform Column Table Association.\\n\\n'\n",
    "    f'Column Name: {col}\\n'\n",
    "    f'Column Cells: {cells}\\n'\n",
    "    f'Candidates: {list(candidates.keys())}\\n\\n'\n",
    "    'Based on the column name and columns cells choose the correct column type among the candidates and return the chosen candidate in the format [[[choosen_type_name]]].\\n'\n",
    "    'Please provide the response strictly in the format [[[choosen_type_name]]]. Do not include any additional text or explanation.\\nExample of your answer:[[[actor]]]'\n",
    "    'Correct candidate: \\n'\n",
    "    )\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the given information, the column name \"col0\" does not provide any context about the type of the column. However, the column cells contain names of places, which can help us determine the type of the column.\n",
      "\n",
      "Looking at the candidates, the most appropriate choice for the column type would be \"locality\" as it refers to a place where a person lives or something is situated.\n",
      "\n",
      "Therefore, the answer is [[[locality]]].\n"
     ]
    }
   ],
   "source": [
    "out = llm.invoke(prompt)\n",
    "print(out.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3257686\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "match = re.search(r'\\[\\[\\[(.*?)\\]\\]\\]', out.content)\n",
    "\n",
    "if match:\n",
    "    name = match.group(1)\n",
    "else:\n",
    "    name = out.content\n",
    "\n",
    "print(candidates[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "landesbühne (lenz)\n",
      "narrative of a second expedition to the shores of the polar sea in the years 1825, 1826, and 1827\n",
      "the life and travels of thomas simpson, the arctic discoverer\n",
      "siegfried lenz\n",
      "john richardson\n",
      "alexander simpson\n",
      "hoffmann und campe\n",
      "john murray\n",
      "richard bentley\n"
     ]
    }
   ],
   "source": [
    "for i, col in enumerate(t.data):\n",
    "    if t.ner[str(i)] == 'NEC':\n",
    "        for cell_content in list(t.data[col]):\n",
    "            print(cell_content)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def C_T_A(t, llm):\n",
    "    '''\n",
    "    t = dataClass.DataTable\n",
    "    llm = langchain model\n",
    "    '''\n",
    "    CTA = {}\n",
    "    for i, col in enumerate(t.data):\n",
    "        if t.ner == None:\n",
    "            print(\"Perform Named Entity Columns Classification first!\")\n",
    "            break\n",
    "        if t.ner[str(i)] == 'NEC':\n",
    "            types = []\n",
    "            for cell_content in list(t.data[col]):\n",
    "                response = LamAPI2(cell_content)\n",
    "                for entity in response[cell_content]:\n",
    "                    for ty in entity['types']:\n",
    "                        types.append(ty)\n",
    "            # Create a counter for the ids\n",
    "            counter = Counter(entity['id'] for entity in types)\n",
    "\n",
    "            # Create a unique list of entities based on 'id'\n",
    "            unique_entities = {entity['id']: entity for entity in types}.values()\n",
    "\n",
    "            # Prepare the data for the dataframe\n",
    "            df_data = []\n",
    "            for entity in unique_entities:\n",
    "                entity_id = entity['id']\n",
    "                entity_name = entity['name']\n",
    "                count = counter[entity_id]\n",
    "                df_data.append({'id': entity_id, 'name': entity_name, 'count': count})\n",
    "\n",
    "            # Create the dataframe\n",
    "            df = pd.DataFrame(df_data)\n",
    "\n",
    "            candidates = {}\n",
    "            for k, (id, name, count) in df.sort_values(by='count', ascending=False).head(25).iterrows():\n",
    "                candidates[name] = id\n",
    "            list(candidates.keys())\n",
    "\n",
    "            cells = list(t.data[col])\n",
    "            prompt = (\n",
    "                'You have to perform Column Table Association.\\n\\n'\n",
    "                f'Column Name: {col}\\n'\n",
    "                f'Column Cells: {cells}\\n'\n",
    "                f'Candidates: {list(candidates.keys())}\\n\\n'\n",
    "                'Based on the column name and columns cells choose the correct column type among the candidates and return the chosen candidate in the format [[[choosen_type_name]]].\\n'\n",
    "                'Please provide the response strictly in the format [[[choosen_type_name]]]. Do not include any additional text or explanation.\\nExample of your answer:[[[actor]]]\\n\\n'\n",
    "                'Correct candidate: \\n'\n",
    "                )\n",
    "            out = llm.invoke(prompt)\n",
    "            match = re.search(r'\\[\\[\\[(.*?)\\]\\]\\]', out.content)\n",
    "            if match:\n",
    "                name = match.group(1)\n",
    "            else:\n",
    "                name = out.content\n",
    "            if name == '' or name == None:\n",
    "                CTA[str(i)] = 'NIL'\n",
    "            else:\n",
    "                CTA[str(i)] = candidates[name]\n",
    "            \n",
    "    return CTA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89GM9ZJW\n",
      "{'0': 'Q11812394', '1': 'Q36180', '2': 'Q1320047'}\n"
     ]
    }
   ],
   "source": [
    "t.cta = C_T_A(t, llm)\n",
    "print(t.name)\n",
    "print(t.cta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CTA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "cta_res = {}\n",
    "for table in tqdm(tables):\n",
    "    t = DataTable(table)\n",
    "    print('##################################')\n",
    "    print(f\"Table Name: {t.name}\")\n",
    "    t.generate_ner_labels(llm)\n",
    "    cta_res[t.name] = C_T_A(t, llm)\n",
    "    json.dump(cta_res, open('results/HardTablesR1/Valid/CTA/Valid.json', 'w'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.3 ('STI')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2268df63e3314f5c0fa267e7a7d58ca881c28135e668c4afe664cdf6d7ddd66d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
