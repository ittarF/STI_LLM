{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os \n",
    "import pandas as pd\n",
    "from dataClass import DataTable\n",
    "from main import list_files_in_folder\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "load_dotenv()\n",
    "\n",
    "f = open('nogit/HardTablesR1_Valid_CEA_ER_ngram.json') \n",
    "\n",
    "data = json.load(f) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein_distance(s1, s2):\n",
    "    \"\"\"\n",
    "    Calculate the Levenshtein distance between two strings.\n",
    "\n",
    "    Parameters:\n",
    "    s1 (str): The first string.\n",
    "    s2 (str): The second string.\n",
    "\n",
    "    Returns:\n",
    "    int: The Levenshtein distance between the two strings.\n",
    "    \"\"\"\n",
    "    if len(s1) < len(s2):\n",
    "        return levenshtein_distance(s2, s1)\n",
    "\n",
    "    # len(s1) >= len(s2)\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "\n",
    "    previous_row = range(len(s2) + 1)\n",
    "    for i, c1 in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            insertions = previous_row[j + 1] + 1\n",
    "            deletions = current_row[j] + 1\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "    \n",
    "    return previous_row[-1]\n",
    "\n",
    "def jaccard_distance(s1, s2, n=1):\n",
    "    \"\"\"\n",
    "    Calculate the Jaccard distance between two strings based on n-grams.\n",
    "\n",
    "    Parameters:\n",
    "    s1 (str): The first string.\n",
    "    s2 (str): The second string.\n",
    "    n (int): The length of n-grams to consider. Default is 1 (character-wise comparison).\n",
    "\n",
    "    Returns:\n",
    "    float: The Jaccard distance between the two strings.\n",
    "    \"\"\"\n",
    "    # Generate n-grams for both strings\n",
    "    def ngrams(string, n):\n",
    "        return {string[i:i+n] for i in range(len(string) - n + 1)}\n",
    "    \n",
    "    set1 = ngrams(s1, n)\n",
    "    set2 = ngrams(s2, n)\n",
    "    \n",
    "    # Calculate the intersection and union of the two sets\n",
    "    intersection = set1.intersection(set2)\n",
    "    union = set1.union(set2)\n",
    "    \n",
    "    # Handle the case where both sets are empty\n",
    "    if not union:\n",
    "        return 0.0\n",
    "    \n",
    "    # Calculate the Jaccard index\n",
    "    jaccard_index = len(intersection) / len(union)\n",
    "    \n",
    "    # Return the Jaccard distance\n",
    "    return 1 - jaccard_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_str(df):\n",
    "    column_names = df.columns.tolist()\n",
    "    table_str = \"col: \"\n",
    "    table_str += \"| \" + \" | \".join(column_names) + \" | \"\n",
    "    for index, row in df.iterrows():\n",
    "        row_str = \" | \" + \" | \".join(str(row[col]) for col in column_names) + \" | \"\n",
    "        table_str += f\"[SEP] col {index + 1}: {row_str}\"\n",
    "    return table_str\n",
    "\n",
    "def candidates_as_str(candidates):\n",
    "    \n",
    "    list_of_candidates = \"\"\n",
    "    for c in candidates:\n",
    "        if c['description'] == '':\n",
    "            c['description'] = 'None'\n",
    "        list_of_candidates += f\"<[ID] {c['id']} [NAME] {c['name']} [DESC] {c['description']} [TYPE] {c['types'][0]['name']}>, \"\n",
    "    \n",
    "    return list_of_candidates[:-2]\n",
    "\n",
    "def build_prompt(table_str, column_name, cell_content, candidates, t_desc):\n",
    "    TASK = \"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\"\n",
    "    INSTRUCTION = \"### Instruction: This is an entity linking task. The goal for this task is to link the selected entity mention in the table cells to the entity in the knowledge base. You will be given a list of referent entities, with each one composed of an entity id, name, its description and its type. Please choose the correct one from the referent entity candidates. Note that the Wikipedia page, Wikipedia section and table caption (if any) provide important information for choosing the correct referent entity.\"\n",
    "    INPUT = f\"### Input: [TLE] {t_desc} [TAB] {table_str}\"\n",
    "    QUESTION = f\"### Question: The selected entity mention in the table cell is: {cell_content}. The column name for ’{cell_content}’ is {column_name}. \"\n",
    "    CANDIDATES = f\"The referent entity candidates are: {candidates}\"\n",
    "    tablellama_prompt = (\n",
    "        f\"{TASK}\\n\\n\"\n",
    "        f\"{INSTRUCTION}\\n\\n\"\n",
    "        f\"{INPUT}\\n\\n\"\n",
    "        f\"{QUESTION}\"\n",
    "        f\"{CANDIDATES}. \\nIf there are no candidates that matched the cell content the response is <NIL>. What is the correct referent entity for the entity mention ’{cell_content}’ ?\\n\\n\"  \n",
    "        \"### Response: \"\n",
    "    )\n",
    "    return tablellama_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_path = 'data/HardTablesR1/DataSets/HardTablesR1/Valid/gt/cea_gt.csv'\n",
    "tables_path = 'data/HardTablesR1/DataSets/HardTablesR1/Valid/tables'\n",
    "\n",
    "gt = pd.read_csv(gt_path, header=None)\n",
    "tables = list_files_in_folder(tables_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "target_names = list(data.keys())\n",
    "print(len(target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1406"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df = gt[gt[0].isin(target_names)]\n",
    "len(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1406it [00:01, 754.92it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "correct = 0\n",
    "for i, (name, r, c, l)  in tqdm(filtered_df.iterrows()):\n",
    "    # print(i, name, c, r, l)\n",
    "    \n",
    "    target_id = l.split('/')[-1]\n",
    "    # print(f\"Ground Truth: {target_id}\")\n",
    "    \n",
    "    ids_list = [d['id'] for d in data[name][str((r, c))]['retrieved_list']]\n",
    "    # print(f\"Target list of ids: {ids_list}\\n\")\n",
    "    # print(f\"Is the ground truth in the target list?\\n{target_id in ids_list}\\n\\n\")\n",
    "    if target_id in ids_list:\n",
    "        correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval Accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "print(f\"Retrieval Accuracy: {correct/len(filtered_df):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompts import generate_tableDesc_prompt, generate_CEA_prompt_with_t_desc, generate_CEA_prompt\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "mistral_api_key = os.getenv(\"MISTRAL_API_KEY\")\n",
    "model_22 = \"open-mixtral-8x22b\"\n",
    "model_7 = \"open-mistral-nemo-2407\"\n",
    "llm_22 = ChatMistralAI(model=model_22, temperature=0, api_key=mistral_api_key)\n",
    "llm_7 = ChatMistralAI(model=model_7, temperature=0, api_key=mistral_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = []\n",
    "export = {}\n",
    "\n",
    "with open('nogit/table_descriptionsHTV.json') as f:\n",
    "    descriptions = json.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Table_name: None\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1406it [00:02, 506.02it/s]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "table_name = None \n",
    "print(f\"\\n\\nTable_name: {table_name}\\n\")\n",
    "y_true, y_pred = [], []\n",
    "for i, (name, r, c, l)  in tqdm(filtered_df.iterrows()):\n",
    "    # print(i, name, c, r, l)\n",
    "    \n",
    "    if name != table_name:\n",
    "        table_name = name\n",
    "        table = DataTable(f\"data/HardTablesR1/DataSets/HardTablesR1/Valid/tables/{name}.csv\")\n",
    "        export[name] = {}\n",
    "        table_as_str = get_table_str(table.data)\n",
    "\n",
    "    # print(table.data)\n",
    "    \n",
    "    target_id = l.split('/')[-1]\n",
    "    # print(f\"\\nGround Truth: {target_id}\\n\")\n",
    "    \n",
    "    ids_list = [d['id'] for d in data[name][str((r, c))]['retrieved_list']]\n",
    "    \n",
    "    if target_id in ids_list:\n",
    "\n",
    "        # Perform CEA:\n",
    "        cell_content = data[name][str((r, c))]['cell']\n",
    "        prompt = generate_CEA_prompt_with_t_desc(table.data, cell_content, candidates_as_str(data[name][str((r, c))]['retrieved_list']), descriptions[name])\n",
    "        prompt_nodesc = generate_CEA_prompt(table.data, cell_content, candidates_as_str(data[name][str((r, c))]['retrieved_list']))\n",
    "        # print(f\"\\nPrompt w. description:\\n{prompt}\\n\\n\")\n",
    "        # print(f\"\\nPrompt without description:\\n{prompt_nodesc}\\n\\n\")\n",
    "        export[name][str((r, c))] = {\n",
    "            'cell': cell_content,\n",
    "            'table_desc': table.t_desc,\n",
    "            'cea_prompt_desc': prompt,\n",
    "            'cea_prompt_nodesc': prompt_nodesc\n",
    "        }\n",
    "# save prompts\n",
    "with open('nogit/prompts_cea_HTV_200_85perc11.json', 'w') as f:\n",
    "    json.dump(export, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_entities = 0\n",
    "for key in export:\n",
    "    tot_entities += len(export[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nogit/prompts_cea_HTV_200_85perc.json') as f:\n",
    "    inputs = json.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = dict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 101/200 [02:00<01:57,  1.19s/it]\n"
     ]
    },
    {
     "ename": "ReadTimeout",
     "evalue": "The read operation timed out",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/STI/lib/python3.12/site-packages/httpx/_transports/default.py:66\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 66\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/miniforge3/envs/STI/lib/python3.12/site-packages/httpx/_transports/default.py:228\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[39mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 228\u001b[0m     resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pool\u001b[39m.\u001b[39;49mhandle_request(req)\n\u001b[1;32m    230\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(resp\u001b[39m.\u001b[39mstream, typing\u001b[39m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/miniforge3/envs/STI/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[39mraise\u001b[39;00m exc \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[39m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[39m# the point at which the response is closed.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/STI/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[39m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mhandle_request(\n\u001b[1;32m    197\u001b[0m         pool_request\u001b[39m.\u001b[39;49mrequest\n\u001b[1;32m    198\u001b[0m     )\n\u001b[1;32m    199\u001b[0m \u001b[39mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[39m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[39m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[39m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[39m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/STI/lib/python3.12/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[39mraise\u001b[39;00m exc\n\u001b[0;32m--> 101\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_connection\u001b[39m.\u001b[39;49mhandle_request(request)\n",
      "File \u001b[0;32m~/miniforge3/envs/STI/lib/python3.12/site-packages/httpcore/_sync/http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_response_closed()\n\u001b[0;32m--> 143\u001b[0m \u001b[39mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/miniforge3/envs/STI/lib/python3.12/site-packages/httpcore/_sync/http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39mwith\u001b[39;00m Trace(\n\u001b[1;32m    105\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mreceive_response_headers\u001b[39m\u001b[39m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    106\u001b[0m ) \u001b[39mas\u001b[39;00m trace:\n\u001b[1;32m    107\u001b[0m     (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m         trailing_data,\n\u001b[0;32m--> 113\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_receive_response_headers(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    114\u001b[0m     trace\u001b[39m.\u001b[39mreturn_value \u001b[39m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m         http_version,\n\u001b[1;32m    116\u001b[0m         status,\n\u001b[1;32m    117\u001b[0m         reason_phrase,\n\u001b[1;32m    118\u001b[0m         headers,\n\u001b[1;32m    119\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/STI/lib/python3.12/site-packages/httpcore/_sync/http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     event \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_receive_event(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    187\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(event, h11\u001b[39m.\u001b[39mResponse):\n",
      "File \u001b[0;32m~/miniforge3/envs/STI/lib/python3.12/site-packages/httpcore/_sync/http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[39mif\u001b[39;00m event \u001b[39mis\u001b[39;00m h11\u001b[39m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 224\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_network_stream\u001b[39m.\u001b[39;49mread(\n\u001b[1;32m    225\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mREAD_NUM_BYTES, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    226\u001b[0m     )\n\u001b[1;32m    228\u001b[0m     \u001b[39m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[39m#\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[39m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[39m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[39m# it as a ConnectError.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/STI/lib/python3.12/site-packages/httpcore/_backends/sync.py:124\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    123\u001b[0m exc_map: ExceptionMapping \u001b[39m=\u001b[39m {socket\u001b[39m.\u001b[39mtimeout: ReadTimeout, \u001b[39mOSError\u001b[39;00m: ReadError}\n\u001b[0;32m--> 124\u001b[0m \u001b[39mwith\u001b[39;49;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49msettimeout(timeout)\n",
      "File \u001b[0;32m~/miniforge3/envs/STI/lib/python3.12/contextlib.py:158\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen\u001b[39m.\u001b[39;49mthrow(value)\n\u001b[1;32m    159\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    160\u001b[0m     \u001b[39m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     \u001b[39m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[39m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/STI/lib/python3.12/site-packages/httpcore/_exceptions.py:14\u001b[0m, in \u001b[0;36mmap_exceptions\u001b[0;34m(map)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(exc, from_exc):\n\u001b[0;32m---> 14\u001b[0m         \u001b[39mraise\u001b[39;00m to_exc(exc) \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mReadTimeout\u001b[0m: The read operation timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m p_desc \u001b[38;5;241m=\u001b[39m v[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcea_prompt_desc\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m p_nodesc \u001b[38;5;241m=\u001b[39m v[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcea_prompt_nodesc\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 6\u001b[0m out_desc \u001b[38;5;241m=\u001b[39m \u001b[43mllm_7\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp_desc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m out_nodesc \u001b[38;5;241m=\u001b[39m llm_7\u001b[38;5;241m.\u001b[39minvoke(p_nodesc)\n\u001b[1;32m      8\u001b[0m outputs[t_name][k][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_desc\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m out_desc\n",
      "File \u001b[0;32m~/miniforge3/envs/STI/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:170\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvoke\u001b[39m(\n\u001b[1;32m    160\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    161\u001b[0m     \u001b[39minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    166\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m BaseMessage:\n\u001b[1;32m    167\u001b[0m     config \u001b[39m=\u001b[39m ensure_config(config)\n\u001b[1;32m    168\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(\n\u001b[1;32m    169\u001b[0m         ChatGeneration,\n\u001b[0;32m--> 170\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_prompt(\n\u001b[1;32m    171\u001b[0m             [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_convert_input(\u001b[39minput\u001b[39;49m)],\n\u001b[1;32m    172\u001b[0m             stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    173\u001b[0m             callbacks\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcallbacks\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    174\u001b[0m             tags\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mtags\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    175\u001b[0m             metadata\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmetadata\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    176\u001b[0m             run_name\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mrun_name\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    177\u001b[0m             run_id\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mpop(\u001b[39m\"\u001b[39;49m\u001b[39mrun_id\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    178\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    179\u001b[0m         )\u001b[39m.\u001b[39mgenerations[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m],\n\u001b[1;32m    180\u001b[0m     )\u001b[39m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/miniforge3/envs/STI/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:599\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_prompt\u001b[39m(\n\u001b[1;32m    592\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    593\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    597\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m    598\u001b[0m     prompt_messages \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mto_messages() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m prompts]\n\u001b[0;32m--> 599\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(prompt_messages, stop\u001b[39m=\u001b[39;49mstop, callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/STI/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:456\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[39mif\u001b[39;00m run_managers:\n\u001b[1;32m    455\u001b[0m             run_managers[i]\u001b[39m.\u001b[39mon_llm_error(e, response\u001b[39m=\u001b[39mLLMResult(generations\u001b[39m=\u001b[39m[]))\n\u001b[0;32m--> 456\u001b[0m         \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    457\u001b[0m flattened_outputs \u001b[39m=\u001b[39m [\n\u001b[1;32m    458\u001b[0m     LLMResult(generations\u001b[39m=\u001b[39m[res\u001b[39m.\u001b[39mgenerations], llm_output\u001b[39m=\u001b[39mres\u001b[39m.\u001b[39mllm_output)  \u001b[39m# type: ignore[list-item]\u001b[39;00m\n\u001b[1;32m    459\u001b[0m     \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results\n\u001b[1;32m    460\u001b[0m ]\n\u001b[1;32m    461\u001b[0m llm_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_combine_llm_outputs([res\u001b[39m.\u001b[39mllm_output \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results])\n",
      "File \u001b[0;32m~/miniforge3/envs/STI/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:446\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[39mfor\u001b[39;00m i, m \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(messages):\n\u001b[1;32m    444\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    445\u001b[0m         results\u001b[39m.\u001b[39mappend(\n\u001b[0;32m--> 446\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate_with_cache(\n\u001b[1;32m    447\u001b[0m                 m,\n\u001b[1;32m    448\u001b[0m                 stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    449\u001b[0m                 run_manager\u001b[39m=\u001b[39;49mrun_managers[i] \u001b[39mif\u001b[39;49;00m run_managers \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    450\u001b[0m                 \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    451\u001b[0m             )\n\u001b[1;32m    452\u001b[0m         )\n\u001b[1;32m    453\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    454\u001b[0m         \u001b[39mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/miniforge3/envs/STI/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:671\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    670\u001b[0m     \u001b[39mif\u001b[39;00m inspect\u001b[39m.\u001b[39msignature(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate)\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 671\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(\n\u001b[1;32m    672\u001b[0m             messages, stop\u001b[39m=\u001b[39;49mstop, run_manager\u001b[39m=\u001b[39;49mrun_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    673\u001b[0m         )\n\u001b[1;32m    674\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    675\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(messages, stop\u001b[39m=\u001b[39mstop, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/STI/lib/python3.12/site-packages/langchain_mistralai/chat_models.py:480\u001b[0m, in \u001b[0;36mChatMistralAI._generate\u001b[0;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m message_dicts, params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[1;32m    479\u001b[0m params \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs}\n\u001b[0;32m--> 480\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompletion_with_retry(\n\u001b[1;32m    481\u001b[0m     messages\u001b[39m=\u001b[39;49mmessage_dicts, run_manager\u001b[39m=\u001b[39;49mrun_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams\n\u001b[1;32m    482\u001b[0m )\n\u001b[1;32m    483\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[0;32m~/miniforge3/envs/STI/lib/python3.12/site-packages/langchain_mistralai/chat_models.py:403\u001b[0m, in \u001b[0;36mChatMistralAI.completion_with_retry\u001b[0;34m(self, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m         _raise_on_error(response)\n\u001b[1;32m    401\u001b[0m         \u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39mjson()\n\u001b[0;32m--> 403\u001b[0m rtn \u001b[39m=\u001b[39m _completion_with_retry(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    404\u001b[0m \u001b[39mreturn\u001b[39;00m rtn\n",
      "File \u001b[0;32m~/miniforge3/envs/STI/lib/python3.12/site-packages/langchain_mistralai/chat_models.py:399\u001b[0m, in \u001b[0;36mChatMistralAI.completion_with_retry.<locals>._completion_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[39mreturn\u001b[39;00m iter_sse()\n\u001b[1;32m    398\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 399\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mpost(url\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m/chat/completions\u001b[39;49m\u001b[39m\"\u001b[39;49m, json\u001b[39m=\u001b[39;49mkwargs)\n\u001b[1;32m    400\u001b[0m     _raise_on_error(response)\n\u001b[1;32m    401\u001b[0m     \u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/miniforge3/envs/STI/lib/python3.12/site-packages/httpx/_client.py:1132\u001b[0m, in \u001b[0;36mClient.post\u001b[0;34m(self, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[1;32m   1111\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(\n\u001b[1;32m   1112\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1113\u001b[0m     url: URLTypes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1125\u001b[0m     extensions: typing\u001b[39m.\u001b[39mOptional[RequestExtensions] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1126\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Response:\n\u001b[1;32m   1127\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39m    Send a `POST` request.\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \n\u001b[1;32m   1130\u001b[0m \u001b[39m    **Parameters**: See `httpx.request`.\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1132\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m   1133\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mPOST\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1134\u001b[0m         url,\n\u001b[1;32m   1135\u001b[0m         content\u001b[39m=\u001b[39;49mcontent,\n\u001b[1;32m   1136\u001b[0m         data\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m   1137\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m   1138\u001b[0m         json\u001b[39m=\u001b[39;49mjson,\n\u001b[1;32m   1139\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m   1140\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m   1141\u001b[0m         cookies\u001b[39m=\u001b[39;49mcookies,\n\u001b[1;32m   1142\u001b[0m         auth\u001b[39m=\u001b[39;49mauth,\n\u001b[1;32m   1143\u001b[0m         follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects,\n\u001b[1;32m   1144\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m   1145\u001b[0m         extensions\u001b[39m=\u001b[39;49mextensions,\n\u001b[1;32m   1146\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/STI/lib/python3.12/site-packages/httpx/_client.py:814\u001b[0m, in \u001b[0;36mClient.request\u001b[0;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[1;32m    799\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(message, \u001b[39mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m    801\u001b[0m request \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuild_request(\n\u001b[1;32m    802\u001b[0m     method\u001b[39m=\u001b[39mmethod,\n\u001b[1;32m    803\u001b[0m     url\u001b[39m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m     extensions\u001b[39m=\u001b[39mextensions,\n\u001b[1;32m    813\u001b[0m )\n\u001b[0;32m--> 814\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(request, auth\u001b[39m=\u001b[39;49mauth, follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects)\n",
      "File \u001b[0;32m~/miniforge3/envs/STI/lib/python3.12/site-packages/httpx/_client.py:901\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    893\u001b[0m follow_redirects \u001b[39m=\u001b[39m (\n\u001b[1;32m    894\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfollow_redirects\n\u001b[1;32m    895\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[1;32m    896\u001b[0m     \u001b[39melse\u001b[39;00m follow_redirects\n\u001b[1;32m    897\u001b[0m )\n\u001b[1;32m    899\u001b[0m auth \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 901\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_handling_auth(\n\u001b[1;32m    902\u001b[0m     request,\n\u001b[1;32m    903\u001b[0m     auth\u001b[39m=\u001b[39;49mauth,\n\u001b[1;32m    904\u001b[0m     follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects,\n\u001b[1;32m    905\u001b[0m     history\u001b[39m=\u001b[39;49m[],\n\u001b[1;32m    906\u001b[0m )\n\u001b[1;32m    907\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    908\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/miniforge3/envs/STI/lib/python3.12/site-packages/httpx/_client.py:929\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    926\u001b[0m request \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(auth_flow)\n\u001b[1;32m    928\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 929\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_handling_redirects(\n\u001b[1;32m    930\u001b[0m         request,\n\u001b[1;32m    931\u001b[0m         follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects,\n\u001b[1;32m    932\u001b[0m         history\u001b[39m=\u001b[39;49mhistory,\n\u001b[1;32m    933\u001b[0m     )\n\u001b[1;32m    934\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    935\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/STI/lib/python3.12/site-packages/httpx/_client.py:966\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_event_hooks[\u001b[39m\"\u001b[39m\u001b[39mrequest\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    964\u001b[0m     hook(request)\n\u001b[0;32m--> 966\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_single_request(request)\n\u001b[1;32m    967\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    968\u001b[0m     \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_event_hooks[\u001b[39m\"\u001b[39m\u001b[39mresponse\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/miniforge3/envs/STI/lib/python3.12/site-packages/httpx/_client.py:1002\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    997\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    998\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    999\u001b[0m     )\n\u001b[1;32m   1001\u001b[0m \u001b[39mwith\u001b[39;00m request_context(request\u001b[39m=\u001b[39mrequest):\n\u001b[0;32m-> 1002\u001b[0m     response \u001b[39m=\u001b[39m transport\u001b[39m.\u001b[39;49mhandle_request(request)\n\u001b[1;32m   1004\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(response\u001b[39m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1006\u001b[0m response\u001b[39m.\u001b[39mrequest \u001b[39m=\u001b[39m request\n",
      "File \u001b[0;32m~/miniforge3/envs/STI/lib/python3.12/site-packages/httpx/_transports/default.py:227\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(request\u001b[39m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m    215\u001b[0m req \u001b[39m=\u001b[39m httpcore\u001b[39m.\u001b[39mRequest(\n\u001b[1;32m    216\u001b[0m     method\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mmethod,\n\u001b[1;32m    217\u001b[0m     url\u001b[39m=\u001b[39mhttpcore\u001b[39m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    225\u001b[0m     extensions\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mextensions,\n\u001b[1;32m    226\u001b[0m )\n\u001b[0;32m--> 227\u001b[0m \u001b[39mwith\u001b[39;49;00m map_httpcore_exceptions():\n\u001b[1;32m    228\u001b[0m     resp \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pool\u001b[39m.\u001b[39;49mhandle_request(req)\n\u001b[1;32m    230\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(resp\u001b[39m.\u001b[39mstream, typing\u001b[39m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/miniforge3/envs/STI/lib/python3.12/contextlib.py:158\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    156\u001b[0m     value \u001b[39m=\u001b[39m typ()\n\u001b[1;32m    157\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen\u001b[39m.\u001b[39;49mthrow(value)\n\u001b[1;32m    159\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    160\u001b[0m     \u001b[39m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     \u001b[39m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[39m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[39mreturn\u001b[39;00m exc \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m value\n",
      "File \u001b[0;32m~/miniforge3/envs/STI/lib/python3.12/site-packages/httpx/_transports/default.py:83\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[39mraise\u001b[39;00m\n\u001b[1;32m     82\u001b[0m message \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(exc)\n\u001b[0;32m---> 83\u001b[0m \u001b[39mraise\u001b[39;00m mapped_exc(message) \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n",
      "\u001b[0;31mReadTimeout\u001b[0m: The read operation timed out"
     ]
    }
   ],
   "source": [
    "for t_name, t_dict in tqdm(inputs.items()):\n",
    "    if t_name not in already_done:\n",
    "        for k, v in t_dict.items():\n",
    "            p_desc = v['cea_prompt_desc']\n",
    "            p_nodesc = v['cea_prompt_nodesc']\n",
    "            out_desc = llm_7.invoke(p_desc)\n",
    "            out_nodesc = llm_7.invoke(p_nodesc)\n",
    "            outputs[t_name][k]['output_desc'] = out_desc\n",
    "            outputs[t_name][k]['output_nodesc'] = out_nodesc\n",
    "            time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 101/200 [00:00<00:00, 14963.25it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'output_desc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m p_nodesc \u001b[38;5;241m=\u001b[39m v[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcea_prompt_nodesc\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#out_desc = llm_7.invoke(p_desc)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#out_nodesc = llm_7.invoke(p_nodesc)\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput_desc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, AIMessage):\n\u001b[1;32m     10\u001b[0m     inputs[t_name][k][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_desc\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m outputs[t_name][k][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_desc\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'output_desc'"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages.ai import AIMessage\n",
    "already_done = []\n",
    "for t_name, t_dict in tqdm(outputs.items()):\n",
    "    for k, v in t_dict.items():\n",
    "        p_desc = v['cea_prompt_desc']\n",
    "        p_nodesc = v['cea_prompt_nodesc']\n",
    "        #out_desc = llm_7.invoke(p_desc)\n",
    "        #out_nodesc = llm_7.invoke(p_nodesc)\n",
    "        if isinstance(outputs[t_name][k]['output_desc'], AIMessage):\n",
    "            inputs[t_name][k]['output_desc'] = outputs[t_name][k]['output_desc'].content\n",
    "        else:\n",
    "            inputs[t_name][k]['output_desc'] = outputs[t_name][k]['output_desc']\n",
    "        if isinstance(outputs[t_name][k]['output_nodesc'], AIMessage):\n",
    "            inputs[t_name][k]['output_nodesc'] = outputs[t_name][k]['output_nodesc'].content\n",
    "        else:\n",
    "            inputs[t_name][k]['output_nodesc'] = outputs[t_name][k]['output_nodesc']\n",
    "\n",
    "    already_done.append(t_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages.ai import AIMessage\n",
    "\n",
    "for t_name, t_dict in tqdm(outputs.items()):\n",
    "    for k, v in t_dict.items():\n",
    "        p_desc = v['cea_prompt_desc']\n",
    "        p_nodesc = v['cea_prompt_nodesc']\n",
    "        out_desc = llm_7.invoke(p_desc)\n",
    "        out_nodesc = llm_7.invoke(p_nodesc)\n",
    "        if isinstance(outputs[t_name][k]['output_desc'], AIMessage):\n",
    "            inputs[t_name][k]['output_desc'] = outputs[t_name][k]['output_desc'].content\n",
    "        else:\n",
    "            inputs[t_name][k]['output_desc'] = outputs[t_name][k]['output_desc']\n",
    "        if isinstance(outputs[t_name][k]['output_nodesc'], AIMessage):\n",
    "            inputs[t_name][k]['output_nodesc'] = outputs[t_name][k]['output_nodesc'].content\n",
    "        else:\n",
    "            inputs[t_name][k]['output_nodesc'] = outputs[t_name][k]['output_nodesc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_name in already_done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "already_done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 180983.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages.ai import AIMessage\n",
    "for t_name, t_dict in tqdm(outputs.items()):\n",
    "    print(t_name not in already_done)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/outputsCEA2.json', 'w') as f:\n",
    "    json.dump(inputs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Table_name: NQK7B1JD\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'NQK7B1JD'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m         prompt_nodesc \u001b[38;5;241m=\u001b[39m generate_CEA_prompt(table\u001b[38;5;241m.\u001b[39mdata, cell_content, candidates_as_str(data[name][\u001b[38;5;28mstr\u001b[39m((r, c))][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretrieved_list\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;66;03m# print(f\"\\nPrompt w. description:\\n{prompt}\\n\\n\")\u001b[39;00m\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;66;03m# print(f\"\\nPrompt without description:\\n{prompt_nodesc}\\n\\n\")\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m         \u001b[43mexport\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;28mstr\u001b[39m((r, c))] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     31\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcell\u001b[39m\u001b[38;5;124m'\u001b[39m: cell_content,\n\u001b[1;32m     32\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtable_desc\u001b[39m\u001b[38;5;124m'\u001b[39m: table\u001b[38;5;241m.\u001b[39mt_desc,\n\u001b[1;32m     33\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcea_prompt_desc\u001b[39m\u001b[38;5;124m'\u001b[39m: prompt,\n\u001b[1;32m     34\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcea_prompt_nodesc\u001b[39m\u001b[38;5;124m'\u001b[39m: prompt_nodesc\n\u001b[1;32m     35\u001b[0m         }\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m        out = llm_7.invoke(prompt)\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;03m        time.sleep(2)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03m        }\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'NQK7B1JD'"
     ]
    }
   ],
   "source": [
    "index = []\n",
    "export = {}\n",
    "print(f\"\\n\\nTable_name: {table_name}\\n\")\n",
    "for i, (name, r, c, l)  in tqdm(filtered_df.iterrows()):\n",
    "    # print(i, name, c, r, l)\n",
    "    \n",
    "    if name != table_name:\n",
    "        table_name = name\n",
    "        table = DataTable(f\"data/HardTablesR1/DataSets/HardTablesR1/Valid/tables/{name}.csv\")\n",
    "        export[name] = {}\n",
    "        # Generate table description\n",
    "        table.generate_t_description(llm_7)\n",
    "        table_as_str = get_table_str(table.data)\n",
    "\n",
    "    # print(table.data)\n",
    "    \n",
    "    target_id = l.split('/')[-1]\n",
    "    # print(f\"\\nGround Truth: {target_id}\\n\")\n",
    "    \n",
    "    ids_list = [d['id'] for d in data[name][str((r, c))]['retrieved_list']]\n",
    "    \n",
    "    if target_id in ids_list:\n",
    "\n",
    "        # Perform CEA:\n",
    "        cell_content = data[name][str((r, c))]['cell']\n",
    "        prompt = generate_CEA_prompt_with_t_desc(table.data, cell_content, candidates_as_str(data[name][str((r, c))]['retrieved_list']), table.t_desc)\n",
    "        prompt_nodesc = generate_CEA_prompt(table.data, cell_content, candidates_as_str(data[name][str((r, c))]['retrieved_list']))\n",
    "        # print(f\"\\nPrompt w. description:\\n{prompt}\\n\\n\")\n",
    "        # print(f\"\\nPrompt without description:\\n{prompt_nodesc}\\n\\n\")\n",
    "        export[name][str((r, c))] = {\n",
    "            'cell': cell_content,\n",
    "            'table_desc': table.t_desc,\n",
    "            'cea_prompt_desc': prompt,\n",
    "            'cea_prompt_nodesc': prompt_nodesc\n",
    "        }\n",
    "        \n",
    "        \n",
    "        \n",
    "'''\n",
    "        out = llm_7.invoke(prompt)\n",
    "        time.sleep(2)\n",
    "        # print(out.content)\n",
    "        y_true.append(target_id)\n",
    "        y_pred.append(out.content)\n",
    "        index.append(i)\n",
    "        export[name][str((r, c))] = {\n",
    "            'cell': cell_content,\n",
    "            'table_desc': table.t_desc,\n",
    "            'cea_prompt': prompt,\n",
    "            'cea_model': llm_7.model,\n",
    "            'model_out': out.content\n",
    "        }\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = [el.strip('[[[').strip(']]]') for el in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.00%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for true, pred in zip(y_true, y_preds):\n",
    "    if true == pred:\n",
    "        correct += 1\n",
    "print(f\"Accuracy: {correct/len(y_true)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nogit/results_8x7_Cea_sub80.json', 'w') as f:\n",
    "    json.dump(export, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giofratti/miniforge3/envs/STI/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "A new version of the following files was downloaded from https://huggingface.co/apple/OpenELM-450M-Instruct:\n",
      "- configuration_openelm.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/apple/OpenELM-450M-Instruct:\n",
      "- modeling_openelm.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(\"apple/OpenELM-450M-Instruct\", trust_remote_code=True) \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"NousResearch/Llama-2-7b-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prompt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Encode the prompt into tokens\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(\u001b[43mprompt\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m55\u001b[39m], return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Generate text\u001b[39;00m\n\u001b[1;32m      5\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m      6\u001b[0m     inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m      7\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39minputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m      8\u001b[0m     max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2000\u001b[39m, \n\u001b[1;32m      9\u001b[0m     pad_token_id\u001b[38;5;241m=\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39meos_token_id\n\u001b[1;32m     10\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prompt' is not defined"
     ]
    }
   ],
   "source": [
    "# Encode the prompt into tokens\n",
    "inputs = tokenizer(prompt[:-55], return_tensors=\"pt\")\n",
    "\n",
    "# Generate text\n",
    "outputs = model.generate(\n",
    "    inputs['input_ids'], \n",
    "    attention_mask=inputs['attention_mask'], \n",
    "    max_length=2000, \n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "# Decode the generated tokens back into text\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(generated_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.3 ('STI')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2268df63e3314f5c0fa267e7a7d58ca881c28135e668c4afe664cdf6d7ddd66d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
