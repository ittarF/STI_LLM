{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os \n",
    "import pandas as pd\n",
    "from dataClass import DataTable\n",
    "from main import list_files_in_folder\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "load_dotenv()\n",
    "\n",
    "f = open('nogit/HardTablesR1_Valid_CEA_ER.json') \n",
    "\n",
    "data = json.load(f) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein_distance(s1, s2):\n",
    "    \"\"\"\n",
    "    Calculate the Levenshtein distance between two strings.\n",
    "\n",
    "    Parameters:\n",
    "    s1 (str): The first string.\n",
    "    s2 (str): The second string.\n",
    "\n",
    "    Returns:\n",
    "    int: The Levenshtein distance between the two strings.\n",
    "    \"\"\"\n",
    "    if len(s1) < len(s2):\n",
    "        return levenshtein_distance(s2, s1)\n",
    "\n",
    "    # len(s1) >= len(s2)\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "\n",
    "    previous_row = range(len(s2) + 1)\n",
    "    for i, c1 in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            insertions = previous_row[j + 1] + 1\n",
    "            deletions = current_row[j] + 1\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "    \n",
    "    return previous_row[-1]\n",
    "\n",
    "def jaccard_distance(s1, s2, n=1):\n",
    "    \"\"\"\n",
    "    Calculate the Jaccard distance between two strings based on n-grams.\n",
    "\n",
    "    Parameters:\n",
    "    s1 (str): The first string.\n",
    "    s2 (str): The second string.\n",
    "    n (int): The length of n-grams to consider. Default is 1 (character-wise comparison).\n",
    "\n",
    "    Returns:\n",
    "    float: The Jaccard distance between the two strings.\n",
    "    \"\"\"\n",
    "    # Generate n-grams for both strings\n",
    "    def ngrams(string, n):\n",
    "        return {string[i:i+n] for i in range(len(string) - n + 1)}\n",
    "    \n",
    "    set1 = ngrams(s1, n)\n",
    "    set2 = ngrams(s2, n)\n",
    "    \n",
    "    # Calculate the intersection and union of the two sets\n",
    "    intersection = set1.intersection(set2)\n",
    "    union = set1.union(set2)\n",
    "    \n",
    "    # Handle the case where both sets are empty\n",
    "    if not union:\n",
    "        return 0.0\n",
    "    \n",
    "    # Calculate the Jaccard index\n",
    "    jaccard_index = len(intersection) / len(union)\n",
    "    \n",
    "    # Return the Jaccard distance\n",
    "    return 1 - jaccard_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_str(df):\n",
    "    column_names = df.columns.tolist()\n",
    "    table_str = \"col: \"\n",
    "    table_str += \"| \" + \" | \".join(column_names) + \" | \"\n",
    "    for index, row in df.iterrows():\n",
    "        row_str = \" | \" + \" | \".join(str(row[col]) for col in column_names) + \" | \"\n",
    "        table_str += f\"[SEP] col {index + 1}: {row_str}\"\n",
    "    return table_str\n",
    "\n",
    "def candidates_as_str(candidates):\n",
    "    \n",
    "    list_of_candidates = \"\"\n",
    "    for c in candidates:\n",
    "        if c['description'] == '':\n",
    "            c['description'] = 'None'\n",
    "        list_of_candidates += f\"<[ID] {c['id']} [NAME] {c['name']} [DESC] {c['description']} [TYPE] {c['types'][0]['name']}>, \"\n",
    "    \n",
    "    return list_of_candidates[:-2]\n",
    "\n",
    "def build_prompt(table_str, column_name, cell_content, candidates, t_desc):\n",
    "    TASK = \"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\"\n",
    "    INSTRUCTION = \"### Instruction: This is an entity linking task. The goal for this task is to link the selected entity mention in the table cells to the entity in the knowledge base. You will be given a list of referent entities, with each one composed of an entity id, name, its description and its type. Please choose the correct one from the referent entity candidates. Note that the Wikipedia page, Wikipedia section and table caption (if any) provide important information for choosing the correct referent entity.\"\n",
    "    INPUT = f\"### Input: [TLE] {t_desc} [TAB] {table_str}\"\n",
    "    QUESTION = f\"### Question: The selected entity mention in the table cell is: {cell_content}. The column name for ’{cell_content}’ is {column_name}. \"\n",
    "    CANDIDATES = f\"The referent entity candidates are: {candidates}\"\n",
    "    tablellama_prompt = (\n",
    "        f\"{TASK}\\n\\n\"\n",
    "        f\"{INSTRUCTION}\\n\\n\"\n",
    "        f\"{INPUT}\\n\\n\"\n",
    "        f\"{QUESTION}\"\n",
    "        f\"{CANDIDATES}. \\nIf there are no candidates that matched the cell content the response is <NIL>. What is the correct referent entity for the entity mention ’{cell_content}’ ?\\n\\n\"  \n",
    "        \"### Response: \"\n",
    "    )\n",
    "    return tablellama_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_path = 'data/HardTablesR1/DataSets/HardTablesR1/Valid/gt/cea_gt.csv'\n",
    "tables_path = 'data/HardTablesR1/DataSets/HardTablesR1/Valid/tables'\n",
    "\n",
    "gt = pd.read_csv(gt_path, header=None)\n",
    "tables = list_files_in_folder(tables_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n"
     ]
    }
   ],
   "source": [
    "target_names = list(data.keys())\n",
    "print(len(target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "535"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df = gt[gt[0].isin(target_names)]\n",
    "len(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "535it [00:00, 45540.30it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "correct = 0\n",
    "for i, (name, r, c, l)  in tqdm(filtered_df.iterrows()):\n",
    "    # print(i, name, c, r, l)\n",
    "    \n",
    "    target_id = l.split('/')[-1]\n",
    "    # print(f\"Ground Truth: {target_id}\")\n",
    "    \n",
    "    ids_list = [d['id'] for d in data[name][str((r, c))]['retrieved_list']]\n",
    "    # print(f\"Target list of ids: {ids_list}\\n\")\n",
    "    # print(f\"Is the ground truth in the target list?\\n{target_id in ids_list}\\n\\n\")\n",
    "    if target_id in ids_list:\n",
    "        correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval Accuracy: 0.56\n"
     ]
    }
   ],
   "source": [
    "print(f\"Retrieval Accuracy: {correct/len(filtered_df):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = data['ZRWO683W']['(1, 0)']['cell']\n",
    "s2 = data['ZRWO683W']['(1, 0)']['retrieved_list'][0]['name'].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def score(s1, s2):\n",
    "    w_lev = 10\n",
    "    w_jac = 8\n",
    "    lev_sim = levenshtein_distance(s1, s2)\n",
    "    jac_sim = jaccard_distance(s1, s2)\n",
    "    \n",
    "    return w_lev*lev_sim + w_jac*jac_sim\n",
    "\n",
    "score(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccard_distance(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ZRWO683W']['(1, 0)']['retrieved_list'][0]\n",
    "prova = [(el['id'], ) for el in data['ZRWO683W']['(1, 0)']['retrieved_list']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompts import generate_tableDesc_prompt, generate_CEA_prompt_with_t_desc\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "mistral_api_key = os.getenv(\"MISTRAL_API_KEY\")\n",
    "model_22 = \"open-mixtral-8x22b\"\n",
    "model_7 = \"open-mixtral-8x7b\"\n",
    "llm_22 = ChatMistralAI(model=model_22, temperature=0, api_key=mistral_api_key)\n",
    "llm_7 = ChatMistralAI(model=model_7, temperature=0, api_key=mistral_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "table_name = None \n",
    "y_true, y_pred = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Table_name: None\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [06:27,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in parsing the ouput\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "535it [14:35,  1.64s/it]\n"
     ]
    }
   ],
   "source": [
    "index = []\n",
    "export = {}\n",
    "print(f\"\\n\\nTable_name: {table_name}\\n\")\n",
    "for i, (name, r, c, l)  in tqdm(filtered_df.iterrows()):\n",
    "    # print(i, name, c, r, l)\n",
    "    \n",
    "    if name != table_name:\n",
    "        table_name = name\n",
    "        table = DataTable(f\"data/HardTablesR1/DataSets/HardTablesR1/Valid/tables/{name}.csv\")\n",
    "        export[name] = {}\n",
    "        # Generate table description\n",
    "        table.generate_t_description(llm_7)\n",
    "        table_as_str = get_table_str(table.data)\n",
    "\n",
    "    # print(table.data)\n",
    "    \n",
    "    target_id = l.split('/')[-1]\n",
    "    # print(f\"\\nGround Truth: {target_id}\\n\")\n",
    "    \n",
    "    ids_list = [d['id'] for d in data[name][str((r, c))]['retrieved_list']]\n",
    "    \n",
    "    if target_id in ids_list:\n",
    "\n",
    "        # Perform CEA:\n",
    "        cell_content = data[name][str((r, c))]['cell']\n",
    "        prompt = generate_CEA_prompt_with_t_desc(table.data, cell_content, candidates_as_str(data[name][str((r, c))]['retrieved_list']), table.t_desc)\n",
    "        #print(f\"\\nPrompt:\\n{prompt}\\n\\n\")\n",
    "        out = llm_7.invoke(prompt)\n",
    "        time.sleep(2)\n",
    "        # print(out.content)\n",
    "        y_true.append(target_id)\n",
    "        y_pred.append(out.content)\n",
    "        index.append(i)\n",
    "        export[name][str((r, c))] = {\n",
    "            'cell': cell_content,\n",
    "            'table_desc': table.t_desc,\n",
    "            'cea_prompt': prompt,\n",
    "            'cea_model': llm_7.model,\n",
    "            'model_out': out.content\n",
    "        }\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = [el.strip('[[[').strip(']]]') for el in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.00%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for true, pred in zip(y_true, y_preds):\n",
    "    if true == pred:\n",
    "        correct += 1\n",
    "print(f\"Accuracy: {correct/len(y_true)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nogit/results_8x7_Cea_sub80.json', 'w') as f:\n",
    "    json.dump(export, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(\"apple/OpenELM-450M-Instruct\", trust_remote_code=True) \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"NousResearch/Llama-2-7b-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the table, table description, cell content and retrieved entities and their types you have to associate the cell content to one of the retrieved entities \n",
      "\n",
      "Table:\n",
      "| col0 | col1 | col2 |\n",
      "|------|------|------|\n",
      "| jelgafell | iceland | nordic volcanological center |\n",
      "| tungurahua voncano | ecuador | instituto geofísico de la escuela politécnica nacional |\n",
      "| kodutka | russia | institute of volcanology and seismology |\n",
      "| amehen | russia | institute of volcanology and seismology |\n",
      "| yoyampplsky | russia | institute of volcanology and seismology |\n",
      "\n",
      "\n",
      "Table Description: {'col0': \"Column 0 contains names of volcanic sites, potentially with unique identifiers. Possible volcano names include 'jelgafell', 'tungurahua voncano', 'kodutka', 'amehen', and 'yoyampplsky'.\", 'col1': \"Column 1 contains country names associated with the volcanic sites. Countries mentioned include 'Iceland', 'Ecuador', and 'Russia'.\", 'col2': \"Column 2 contains the names of organizations responsible for monitoring and studying the volcanic sites. These organizations include 'nordic volcanological center', 'instituto geofísico de la escuela politécnica nacional', and 'institute of volcanology and seismology'.\"}\n",
      "\n",
      "Cell Content: russia\n",
      "\n",
      "Retrieved Entities and their types: <[ID] Q7382106 [NAME] Russian Prussia [DESC] periods of Prussian history while under Russian control (1758-63, 1945-present) [TYPE] None>, <[ID] Q7406484 [NAME] Russia [DESC] land warfare branch of El Salvador's military [TYPE] army>, <[ID] Q114108237 [NAME] Russia [DESC] scientific article published in 2016 [TYPE] scholarly article>, <[ID] Q159 [NAME] Russia [DESC] sovereign state in Eastern Europe and Northern Asia [TYPE] sovereign state>, <[ID] Q7381938 [NAME] Russia [DESC] horse [TYPE] horse>, <[ID] Q63315138 [NAME] Russia [DESC] 1877 edition of book by Donald Mackenzie Wallace [TYPE] version, edition or translation>, <[ID] Q3804664 [NAME] Russia [DESC] Hetalia character [TYPE] manga character>, <[ID] Q71873137 [NAME] Russia [DESC] journal article; published in Nature on 2005-11-01 [TYPE] scholarly article>, <[ID] Q398720 [NAME] Russia [DESC] Wikimedia disambiguation page [TYPE] Wikimedia disambiguation page>, <[ID] Q23890440 [NAME] Russia [DESC] genus of Ostracoda [TYPE] fossil taxon>, <[ID] Q20655465 [NAME] Russia [DESC] encyclopedic article in  EB11 [TYPE] encyclopedia article>, <[ID] Q114525428 [NAME] Russia [DESC] episode of Wildboyz (S4 E2) [TYPE] television series episode>, <[ID] Q60304892 [NAME] Russia [DESC] a scholarly article [TYPE] scholarly article>, <[ID] Q34266 [NAME] Russia [DESC] former empire in Eurasia and North America (1721–1917) [TYPE] empire>, <[ID] Q24058892 [NAME] Russia [DESC] painting by Timur Novikov [TYPE] painting>, <[ID] Q2184 [NAME] Russia [DESC] constituent republic of the Soviet Union (1922–1991) [TYPE] historical country>, <[ID] Q42195226 [NAME] Russia [DESC] None [TYPE] creative work>, <[ID] Q85764552 [NAME] Russia [DESC] climate changing gases from the Eurasian country [TYPE] Wikipedia overview article>\n",
      "\n",
      "Classification Request:\n",
      " Study the table and the retrieved entities along with their types then associate the cell to the correct entity choosen between the list of retrieved entities.\n",
      "Please provide the response strictly in the format [[[choosen_entity_id]]]. Do not include any additional text or explanation.\n",
      "\n",
      "Example:\n",
      "[Q85764552] Russia\n",
      "\n",
      "[Q85764552:CELL] cell content = \"Cell 85764552 contains the name 'Russia'. This entity is associated with cell 85764552 cell content cell 85764552 cell type = ENTITY] chosen_entity_id = Q85764552\n",
      "\n",
      "[Q2184] Russia\n",
      "\n",
      "[Q2184:CELL] cell content = \"Cell 2184 contains the name 'Russia'. This entity is associated with cell 2184 cell content cell 2184 cell type = ENTITY] chosen_entity_id = Q2184\n",
      "\n",
      "[Q114525428] Russia\n",
      "\n",
      "[Q114525428:CELL] cell content = \"Cell 114525428 contains the name 'Wikimedia disambiguation page'. This entity is associated with cell 114525428 cell content cell 114525428 cell type = ENTITY] chosen_entity_id = Q114525428]\n",
      "\n",
      "[Q3804664] Russia\n",
      "\n",
      "[Q3804664:CELL] cell content = \"Cell 3804664 contains the name 'Hetalia character'. This entity is associated with cell 3804664 cell content cell 3804664 cell type = ENTITY] chosen_entity_id = Q3804664]\n",
      "\n",
      "[Q23890440] Russia\n",
      "\n",
      "[Q23890440:CELL] cell content = \"Cell 23890440 contains the name 'Wikimedia disambiguation page'. This entity is associated with cell 23890440 cell content cell 23890440 cell type = ENTITY] chosen_entity_id = Q23890440]\n",
      "\n",
      "[Q34266] Russia\n",
      "\n",
      "[Q34266:CELL] cell content = \"Cell 34266 contains the name 'encyclopedic article in  EB11'. This entity is associated with cell 34266 cell content cell 34266 cell type = ENTITY] chosen_entity_id = Q34266]\n",
      "\n",
      "[Q114525428:TYPE] None\n",
      "\n",
      "[Q114525428:TYPE:DESC] period of Prussia (1758-63)\n",
      "\n",
      "[Q85764552:TYPE] ENTITY\n",
      "\n",
      "[Q85764552:TYPE:DESC] Russian Prussia\n",
      "\n",
      "[Q2184:TYPE] ENTITY\n",
      "\n",
      "[Q2184:TYPE:DESC] Russian constituent republic of the Soviet Union (1922-1991)\n",
      "\n",
      "[Q42195226:TYPE] ENTITY\n",
      "\n",
      "[Q42195226:TYPE:DESC] Russia\n",
      "\n",
      "[Q85764552:CELL:TYPE] ENTITY\n",
      "\n",
      "[Q85764552:CELL:TYPE:DESC] Cell type (one of [[[cell_type]], [[cell_type_name]]])\n",
      "\n",
      "cell_type = [[cell_type_id], [[cell_type_name]]]\n",
      "\n",
      "[Q23890440:CELL:TYPE] ENTITY\n",
      "\n",
      "[Q23890440:CELL:TYPE:DESC] Cell content (one of [[[cell_content]], [[cell_content_name]]])\n",
      "\n",
      "cell_content = [[cell_content_\n"
     ]
    }
   ],
   "source": [
    "# Encode the prompt into tokens\n",
    "inputs = tokenizer(prompt[:-55], return_tensors=\"pt\")\n",
    "\n",
    "# Generate text\n",
    "outputs = model.generate(\n",
    "    inputs['input_ids'], \n",
    "    attention_mask=inputs['attention_mask'], \n",
    "    max_length=2000, \n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "# Decode the generated tokens back into text\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(generated_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.3 ('STI')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2268df63e3314f5c0fa267e7a7d58ca881c28135e668c4afe664cdf6d7ddd66d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
